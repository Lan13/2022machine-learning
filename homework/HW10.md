# HW10

PB20111689 蓝俊玮

## T1

因为有：
$$
\sum\limits_{c}P(c|\pmb{x})P(c|\pmb{z})\le\max_{c\in\mathcal{Y}}P(c|\pmb{x})\sum_{c}P(c|\pmb{z})=\max_{c\in\mathcal{Y}}P(c|\pmb{x})\
$$
所以可以得到：
$$
err^*(\pmb{x})=1-\max_{c\in\mathcal{Y}}P(c|\pmb{x})\le1-\sum\limits_{c}P(c|\pmb{x})P(c|\pmb{z})=err(\pmb{x})
$$
记 $err^*(\pmb{x})=1-P(c^*|\pmb{x})$ 同时也有：
$$
\begin{aligned}
err(\pmb{x})=&1-\sum\limits_{c}P(c|\pmb{x})P(c|\pmb{z})\\
\approx&1-\sum_{c}P^2(c|\pmb{x})\\
=&1-P^2(c^*|\pmb{x})-\sum_{c\ne c^*}P^2(c|\pmb{x})\\
=&(1+P(c^*|\pmb{x}))(1-P(c^*|\pmb{x}))-\sum_{c\ne c^*}P^2(c|\pmb{x})\\
=&(2-err^*(\pmb{x}))err^*(\pmb{x})-\sum_{c\ne c^*}P^2(c|\pmb{x})\\
\end{aligned}
$$
由柯西不等式可以得到：
$$
\sum_{c\ne c^*}P^2(c|\pmb{x})\ge\frac{1}{|\mathcal{Y}|-1}(\sum_{c\ne c^*}P(c|\pmb{x}))^2=\frac{1}{|\mathcal{Y}|-1}(1-P(c^*|\pmb{x}))^2=\frac{1}{|\mathcal{Y}|-1}(err^*(\pmb{x}))^2
$$
将该式代入前式，可以得到：
$$
\begin{align}
err(\pmb{x})\le&(2-err^*(\pmb{x}))err^*(\pmb{x})-\frac{1}{|\mathcal{Y}|-1}(err^*(\pmb{x}))^2\\
=&err^*(\pmb{x})(2-\frac{|\mathcal{Y}|}{|\mathcal{Y}|-1}\times err^*(\pmb{x}))
\end{align}
$$
综上所述，可以知道：
$$
err^*(\pmb{x})\le err(\pmb{x})\le err^*(\pmb{x})(2-\frac{|\mathcal{Y}|}{|\mathcal{Y}|-1}\times err^*(\pmb{x}))
$$

## T2

> 在实践中，协方差矩阵 $\pmb{X}\pmb{X}^T$ 的特征值分解常由中心化后的样本矩阵 $\pmb{X}$ 的奇异值分解代替，试述其原因

$\pmb{X}$ 有奇异值分解为 $\pmb{X}=\pmb{U}\pmb{\Sigma}\pmb{V}^T$，则 $\pmb{X}\pmb{X}^T=\pmb{U}\pmb{\Sigma}\pmb{V}^T\pmb{V}\pmb{\Sigma}^T\pmb{U}^T$，而 $\pmb{V}^T\pmb{V}=\pmb{I}$，因此有 $\pmb{X}\pmb{X}^T=\pmb{U}\pmb{\Sigma}\pmb{\Sigma}^T\pmb{U}^T=\pmb{U}\pmb{\Lambda}\pmb{U}^T$。

而对 $\pmb{X}\pmb{X}^T$ 特征值分解有 $\pmb{X}\pmb{X}^T=\pmb{P}\pmb{\Lambda}\pmb{P}^T$。只要让 $\pmb{P}=\pmb{U}$，所以可以用奇异值分解来代替特征值分解，可以节省计算和存储的成本，且计算精度较高。

## T3

$$
L(\pmb{W})=\tr(\pmb{W}^T\pmb{X}\pmb{X}^T\pmb{W})-\tr(\Lambda^T(\pmb{W}^T\pmb{W}-\pmb{I}_{d'}))\\
\frac{\part L(\pmb{W})}{\part \pmb{W}}=(\pmb{X}\pmb{X}^T+\pmb{X}\pmb{X}^T)\pmb{W}-(\pmb{W}\Lambda+\pmb{W}\Lambda^T)=2\pmb{X}\pmb{X}^T\pmb{W}-2\pmb{W}\Lambda
$$

令 $\frac{\part L(\pmb{W})}{\part \pmb{W}}=0$，可以求得：
$$
\pmb{X}\pmb{X}^T\pmb{W}=\pmb{W}\Lambda
$$
将 $\pmb{W}$ 和 $\Lambda$ 展开（对协方差矩阵 $\pmb{X}\pmb{X}^T$ 进行特征值分解并将特征值进行排序），可以得到：
$$
\pmb{X}\pmb{X}^T\pmb{w}_i=\lambda_i\pmb{w}_i\quad i=1,2,...,d'
$$
将特征向量构成 $\pmb{W}=(\pmb{w}_1,\pmb{w}_2,...,\pmb{w}_{d'})$ 就是主成分分析的解。

## T4

不是凸优化问题。因为 $P$ 不能满足是凸集。

同时
$$
f(P)=\sum_{(x_i,x_j)\in\mathcal{M}}(x_i-x_j)^TPP^T(x_i-x_j)\\
g(P)=1-\sum_{(x_i,x_j)\in\mathcal{M}}(x_i-x_j)^TPP^T(x_i-x_j)
$$
则对于原问题就有：
$$
\min_{P}f(P)\quad s.t.\ g(P)\le0
$$
可知 $f(P)$ 和 $g(P)$ 的二阶导数符号是相反的，因此 $f(P)$ 和 $g(P)$ 不能同时为凸函数，因此不是凸优化问题。
